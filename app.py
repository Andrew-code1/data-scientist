# backdata_dashboard.py
"""êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (Streamlit + DuckDB)

ğŸ“Œ **2025â€‘08â€‘01 ì—…ë°ì´íŠ¸**

1. **ì „ì²´ ì„ íƒ / ì „ì²´ í•´ì œ** ë²„íŠ¼ (ë©€í‹°ì…€ë ‰íŠ¸ ì•ˆì • ì²˜ë¦¬: `on_click` ì´ìš©)
2. **ìì¬ëª… ì™€ì¼ë“œì¹´ë“œ**: `*`â†’`%` ì¹˜í™˜ (ì˜ˆ: `*í¼í“¸*1L*`)
3. **ì›”ë³„ ì‹œê³„ì—´ (YYYYë…„MMì›”)** + Altair íˆ´íŒ
4. **ê³µê¸‰ì—…ì²´ í•„í„°**: `ì½”ë“œ_ì—…ì²´ëª…` í˜•ì‹, ë¬¸ìì—´ ê²€ìƒ‰ ê°€ëŠ¥

ì‹¤í–‰::
    streamlit run backdata_dashboard.py
"""
from __future__ import annotations

from io import BytesIO
from typing import List, Optional

import altair as alt
import duckdb
import pandas as pd
import streamlit as st

st.set_page_config(page_title="êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", layout="wide")

# ---------------------------------------------------------------------------
# ğŸ“š ë°ì´í„° ë¡œë”© & ì „ì²˜ë¦¬
# ---------------------------------------------------------------------------

def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = df.columns.str.strip()
    rename_map: dict[str, str] = {}
    for col in df.columns:
        if col == "ê³µê¸‰ì—…ì²´ëª…":
            continue
        if "ê³µê¸‰ì—…ì²´" in col or "ê³µê¸‰ì‚¬" in col:
            rename_map[col] = "ê³µê¸‰ì—…ì²´ëª…"
        elif col.replace(" ", "") == "êµ¬ë§¤ê·¸ë£¹ëª…":
            rename_map[col] = "êµ¬ë§¤ê·¸ë£¹"
        elif col.replace(" ", "") == "ê³µê¸‰ì—…ì²´ì½”ë“œ":
            rename_map[col] = "ê³µê¸‰ì—…ì²´ì½”ë“œ"
    if rename_map:
        df = df.rename(columns=rename_map)
    if df.columns.duplicated().any():
        df = df.loc[:, ~df.columns.duplicated()]
    return df


def load_csv(upload: BytesIO) -> pd.DataFrame:
    df = pd.read_csv(upload, encoding="cp949", low_memory=False)
    df = _standardize_columns(df)

    if "ë§ˆê°ì›”" not in df.columns:
        st.error("âš ï¸ 'ë§ˆê°ì›”' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í—¤ë”ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    df["ë§ˆê°ì›”"] = pd.to_datetime(df["ë§ˆê°ì›”"], errors="coerce")
    df["ì—°ë„"] = df["ë§ˆê°ì›”"].dt.year.astype("Int64")
    df["ì—°ì›”"] = df["ë§ˆê°ì›”"].dt.to_period("M").dt.to_timestamp()

    num_cols: List[str] = [c for c in ["ì†¡ì¥ìˆ˜ëŸ‰", "ì†¡ì¥ê¸ˆì•¡", "ë‹¨ê°€", "í”ŒëœíŠ¸", "êµ¬ë§¤ê·¸ë£¹"] if c in df.columns]
    if num_cols:
        df[num_cols] = df[num_cols].apply(pd.to_numeric, errors="coerce").fillna(0)

    if "ê³µê¸‰ì—…ì²´ëª…" in df.columns:
        df["ê³µê¸‰ì—…ì²´ëª…"] = df["ê³µê¸‰ì—…ì²´ëª…"].astype(str).str.strip()
    if "ê³µê¸‰ì—…ì²´ì½”ë“œ" in df.columns:
        df["ê³µê¸‰ì—…ì²´ì½”ë“œ"] = df["ê³µê¸‰ì—…ì²´ì½”ë“œ"].astype(str).str.strip()
        df["ì—…ì²´í‘œì‹œ"] = df["ê³µê¸‰ì—…ì²´ì½”ë“œ"].str.zfill(5) + "_" + df["ê³µê¸‰ì—…ì²´ëª…"].fillna("")
    elif "ê³µê¸‰ì—…ì²´ëª…" in df.columns:
        df["ì—…ì²´í‘œì‹œ"] = df["ê³µê¸‰ì—…ì²´ëª…"]

    return df

# ---------------------------------------------------------------------------
# ğŸ”§ í—¬í¼
# ---------------------------------------------------------------------------

def sql_list_num(vals: list[int]) -> str:
    return ",".join(map(str, vals)) if vals else "-1"


def sql_list_str(vals: list[str]) -> str:
    if not vals:
        return "''"
    esc = [v.replace("'", "''") for v in vals]
    return ",".join(f"'{v}'" for v in esc)

# ---------------------------------------------------------------------------
# ğŸ›ï¸ ë©€í‹°ì…€ë ‰íŠ¸ + ì „ì²´/í•´ì œ ìœ„ì ¯ (ë²„íŠ¼ ì½œë°±)
# ---------------------------------------------------------------------------

def _set_all(key: str, values: list):
    st.session_state[key] = values


def _clear_all(key: str):
    st.session_state[key] = []


def multiselect_with_toggle(label: str, options: list, key_prefix: str):
    ms_key = f"{key_prefix}_ms"
    if ms_key not in st.session_state:
        st.session_state[ms_key] = options  # ì´ˆê¸°ê°’: ì „ì²´ ì„ íƒ

    cols = st.columns([3, 1, 1])
    with cols[0]:
        selected = st.multiselect(label, options, key=ms_key)
    with cols[1]:
        st.button("ì „ì²´", key=f"{key_prefix}_all", on_click=_set_all, args=(ms_key, options))
    with cols[2]:
        st.button("í•´ì œ", key=f"{key_prefix}_none", on_click=_clear_all, args=(ms_key,))
    return selected

# ---------------------------------------------------------------------------
# ğŸ“‚ íŒŒì¼ ì—…ë¡œë“œ (ì‚¬ì´ë“œë°”)
# ---------------------------------------------------------------------------
with st.sidebar:
    st.header("CSV ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("backdata.csv (cp949)", type="csv")

if uploaded_file is not None:
    if st.session_state.get("file_name") != uploaded_file.name:
        st.session_state["df"] = load_csv(uploaded_file)
        st.session_state["file_name"] = uploaded_file.name
    df: Optional[pd.DataFrame] = st.session_state["df"]
else:
    st.info("ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    df = None

# ---------------------------------------------------------------------------
# ğŸ–¥ï¸ ëŒ€ì‹œë³´ë“œ
# ---------------------------------------------------------------------------
if df is not None and not df.empty:
    con = duckdb.connect(database=":memory:")
    con.register("data", df)

    # -------- ì‚¬ì´ë“œë°” í•„í„° --------
    with st.sidebar:
        st.header("í•„í„° ì¡°ê±´")
        years_all = df["ì—°ë„"].dropna().astype(int).sort_values().tolist()
        plants_all = df["í”ŒëœíŠ¸"].dropna().astype(int).sort_values().tolist() if "í”ŒëœíŠ¸" in df.columns else []
        groups_all = df["êµ¬ë§¤ê·¸ë£¹"].dropna().astype(int).sort_values().tolist() if "êµ¬ë§¤ê·¸ë£¹" in df.columns else []
        suppliers_all = df["ì—…ì²´í‘œì‹œ"].dropna().sort_values().tolist() if "ì—…ì²´í‘œì‹œ" in df.columns else []

        sel_years = multiselect_with_toggle("ì—°ë„", years_all, "yr")
        sel_plants = multiselect_with_toggle("í”ŒëœíŠ¸", plants_all, "pl") if plants_all else []
        sel_groups = multiselect_with_toggle("êµ¬ë§¤ê·¸ë£¹", groups_all, "gr") if groups_all else []
        sel_suppliers = multiselect_with_toggle("ê³µê¸‰ì—…ì²´", suppliers_all, "sp") if suppliers_all else []

    where_clauses = [f"ì—°ë„ IN ({sql_list_num(sel_years)})"]
    if plants_all:
        where_clauses.append(f"í”ŒëœíŠ¸ IN ({sql_list_num(sel_plants)})")
    if groups_all:
        where_clauses.append(f"êµ¬ë§¤ê·¸ë£¹ IN ({sql_list_num(sel_groups)})")
    if suppliers_all:
        supplier_names = [s.split("_", 1)[1] if "_" in s else s for s in sel_suppliers]
        where_clauses.append(f"ê³µê¸‰ì—…ì²´ëª… IN ({sql_list_str(supplier_names)})")

    filter_where = " WHERE " + " AND ".join(where_clauses)

    # -------- ì›”ë³„ ì‹œê³„ì—´ --------
    month_df = con.execute(
        f"""
        SELECT date_trunc('month', ë§ˆê°ì›”) AS ì—°ì›”,
               ROUND(SUM(ì†¡ì¥ìˆ˜ëŸ‰) / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
               ROUND(SUM(ì†¡ì¥ê¸ˆì•¡) / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
        FROM data
        {filter_where}
        GROUP BY 1
        ORDER BY 1
        """
    ).fetchdf()

    month_df["ì—°ì›”í‘œì‹œ"] = month_df["ì—°ì›”"].dt.strftime("%Yë…„%mì›”")

    st.title("ğŸ“ˆ ì›”ë³„ êµ¬ë§¤ í˜„í™©")
    st.dataframe(month_df[["ì—°ì›”í‘œì‹œ", "ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA", "ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›"]], hide_index=True, use_container_width=True)

    if not month_df.empty:
        chart = (
            alt.Chart(month_df)
            .transform_fold(["ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA", "ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›"], as_["ì§€í‘œ", "ê°’"])
            .mark_line(point=True)
            .encode(
                x=alt.X("ì—°ì›”:T", title="ì—°ì›”"),
                y=alt.Y("ê°’:Q", title="ê°’"),
                color="ì§€í‘œ:N",
                tooltip=["ì—°ì›”í‘œì‹œ:N", "ì§€í‘œ:N", "ê°’:Q"],
            )
            .interactive()
        )
        st.altair_chart(chart, use_container_width=True)
    st.caption("ë‹¨ìœ„: ì†¡ì¥ìˆ˜ëŸ‰ = ì²œ EA, ì†¡ì¥ê¸ˆì•¡ = ë°±ë§Œ ì›")

    # -------- ì—…ì²´ë³„ ì§‘ê³„ --------
    if suppliers_all:
        sup_df = con.execute(
            f"""
            SELECT ê³µê¸‰ì—…ì²´ëª…,
                   ROUND(SUM(ì†¡ì¥ìˆ˜ëŸ‰) / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
                   ROUND(SUM(ì†¡ì¥ê¸ˆì•¡) / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
            FROM data
            {filter_where}
            GROUP BY 1
            ORDER BY 2 DESC
            """
        ).fetchdf()

        st.markdown("---")
        st.header("ğŸ¢ ì—…ì²´ë³„ êµ¬ë§¤ í˜„í™©")
        st.dataframe(sup_df, hide_index=True, use_container_width=True)

        if not sup_df.empty:
            sup_csv = sup_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button("ì—…ì²´ë³„ CSV ë‹¤ìš´ë¡œë“œ", sup_csv, file_name="supplier_summary.csv", mime="text/csv")

    # -------- ìì¬ëª… ê²€ìƒ‰ --------
    st.markdown("---")
    st.header("ğŸ” ìì¬ëª… ê²€ìƒ‰ (ì™€ì¼ë“œì¹´ë“œ: *)")
    pattern = st.text_input("ìì¬ëª… íŒ¨í„´", placeholder="ì˜ˆ) *í¼í“¸*1L*")

    if pattern:
        pattern_sql = pattern.replace("*", "%").replace("'", "''")
        search_where = filter_where + f" AND ìì¬ëª… ILIKE '{pattern_sql}'"
        base_cols = ["ë§ˆê°ì›”", "ì—°ì›”", "ì—°ë„", "í”ŒëœíŠ¸", "êµ¬ë§¤ê·¸ë£¹"]
        if suppliers_all:
            base_cols.append("ê³µê¸‰ì—…ì²´ëª…")
        select_cols = ", ".join(base_cols) + ", ìì¬ AS ìì¬ì½”ë“œ, ìì¬ëª…, ROUND(ì†¡ì¥ìˆ˜ëŸ‰ / 1000, 2) AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA, ROUND(ì†¡ì¥ê¸ˆì•¡ / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›"

        search_df = con.execute(
            f"SELECT {select_cols} FROM data {search_where} ORDER BY ë§ˆê°ì›”"
        ).fetchdf()

        st.write(f"ê²€ìƒ‰ ê²°ê³¼: **{len(search_df):,}ê±´** ì¼ì¹˜")
        st.dataframe(search_df, use_container_width=True)

        if not search_df.empty:
            csv_bytes = search_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button("CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, file_name="search_results.csv", mime="text/csv")
