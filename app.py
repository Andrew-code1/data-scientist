# backdata_dashboard.py
"""êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (Streamlit + DuckDB)

[ì—…ë°ì´íŠ¸ âš™ï¸]
1. **ì „ì²´â€‘ì„ íƒ / ì „ì²´â€‘í•´ì œ** ë²„íŠ¼(ì—°ë„â€§í”ŒëœíŠ¸â€§êµ¬ë§¤ê·¸ë£¹â€§ê³µê¸‰ì—…ì²´) ì¶”ê°€
2. **ìì¬ëª… ì™€ì¼ë“œì¹´ë“œ ê²€ìƒ‰** â”€ `*` â†’ SQL `%` ë¡œ ë§¤í•‘ (ì˜ˆ: `*í¼í“¸*1L*`)
3. **ì›”ë³„ ì‹œê³„ì—´** (`YYYYë…„MMì›”`) + Altair íˆ´íŒ ì§€ì›
4. **ê³µê¸‰ì—…ì²´ í•„í„°**: `ì½”ë“œ_ì—…ì²´ëª…` í˜•ì‹ìœ¼ë¡œ í‘œì‹œí•´ ì´ë¦„Â·ì½”ë“œ ëª¨ë‘ ê²€ìƒ‰ ê°€ëŠ¥

ì‹¤í–‰::
    streamlit run backdata_dashboard.py
"""

from __future__ import annotations

from io import BytesIO
from typing import List, Optional

import duckdb
import pandas as pd
import streamlit as st
import altair as alt

st.set_page_config(page_title="êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", layout="wide")

# ---------------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------------------------

def _standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """ê³µë°± ì œê±°Â·ìœ ì‚¬ í—¤ë” í†µí•©Â·ì¤‘ë³µ ì—´ ì œê±°"""
    df.columns = df.columns.str.strip()
    rename_map: dict[str, str] = {}
    for col in df.columns:
        if col == "ê³µê¸‰ì—…ì²´ëª…":
            continue
        if "ê³µê¸‰ì—…ì²´" in col or "ê³µê¸‰ì‚¬" in col:
            rename_map[col] = "ê³µê¸‰ì—…ì²´ëª…"
        elif col.replace(" ", "") == "êµ¬ë§¤ê·¸ë£¹ëª…":
            rename_map[col] = "êµ¬ë§¤ê·¸ë£¹"
        elif col.replace(" ", "") == "ê³µê¸‰ì—…ì²´ì½”ë“œ":
            rename_map[col] = "ê³µê¸‰ì—…ì²´ì½”ë“œ"
    if rename_map:
        df = df.rename(columns=rename_map)
    if df.columns.duplicated().any():
        df = df.loc[:, ~df.columns.duplicated()]
    return df


def load_csv(upload: BytesIO) -> pd.DataFrame:
    df = pd.read_csv(upload, encoding="cp949", low_memory=False)
    df = _standardize_columns(df)

    if "ë§ˆê°ì›”" not in df.columns:
        st.error("âš ï¸ 'ë§ˆê°ì›”' ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í—¤ë”ë¥¼ í™•ì¸í•´ ì£¼ì„¸ìš”.")
        st.stop()

    # ë‚ ì§œ ë³€í™˜ & íŒŒìƒ ì—°Â·ì›”
    df["ë§ˆê°ì›”"] = pd.to_datetime(df["ë§ˆê°ì›”"], errors="coerce")
    df["ì—°ë„"] = df["ë§ˆê°ì›”"].dt.year.astype("Int64")
    df["ì—°ì›”"] = df["ë§ˆê°ì›”"].dt.to_period("M").dt.to_timestamp()

    # ìˆ«ì ì»¬ëŸ¼ ì •ë¦¬
    num_cols: List[str] = [c for c in ["ì†¡ì¥ìˆ˜ëŸ‰", "ì†¡ì¥ê¸ˆì•¡", "ë‹¨ê°€", "í”ŒëœíŠ¸", "êµ¬ë§¤ê·¸ë£¹"] if c in df.columns]
    if num_cols:
        df[num_cols] = df[num_cols].apply(lambda s: pd.to_numeric(s, errors="coerce")).fillna(0)

    # ê³µê¸‰ì—…ì²´ ì •ë³´ ì •ë¦¬
    if "ê³µê¸‰ì—…ì²´ëª…" in df.columns:
        df["ê³µê¸‰ì—…ì²´ëª…"] = df["ê³µê¸‰ì—…ì²´ëª…"].astype(str).str.strip()
    if "ê³µê¸‰ì—…ì²´ì½”ë“œ" in df.columns:
        df["ê³µê¸‰ì—…ì²´ì½”ë“œ"] = df["ê³µê¸‰ì—…ì²´ì½”ë“œ"].astype(str).str.strip()
        # í‘œì‹œìš© ì»¬ëŸ¼ (ì½”ë“œ_ì´ë¦„)
        df["ì—…ì²´í‘œì‹œ"] = df["ê³µê¸‰ì—…ì²´ì½”ë“œ"].str.zfill(5) + "_" + df["ê³µê¸‰ì—…ì²´ëª…"].fillna("")
    elif "ê³µê¸‰ì—…ì²´ëª…" in df.columns:
        df["ì—…ì²´í‘œì‹œ"] = df["ê³µê¸‰ì—…ì²´ëª…"]

    return df


def sql_list_num(values: list[int]) -> str:
    return ",".join(map(str, values)) if values else "-1"


def sql_list_str(values: list[str]) -> str:
    if not values:
        return "''"
    esc = [v.replace("'", "''") for v in values]
    return ",".join(f"'{v}'" for v in esc)

# ---------------------------------------------------------------------------
# ê³µí†µ ìœ„ì ¯: ë©€í‹°ì…€ë ‰íŠ¸ + ì „ì²´/í•´ì œ ë²„íŠ¼
# ---------------------------------------------------------------------------

def multiselect_with_toggle(label: str, options: list, default: list, key_prefix: str):
    ms_key = f"{key_prefix}_ms"
    if ms_key not in st.session_state:
        st.session_state[ms_key] = default

    cols = st.columns([3, 1, 1])
    with cols[0]:
        selected = st.multiselect(label, options, default=st.session_state[ms_key], key=ms_key)
    with cols[1]:
        if st.button("ì „ì²´", key=f"{key_prefix}_all"):
            st.session_state[ms_key] = options
            selected = options
    with cols[2]:
        if st.button("í•´ì œ", key=f"{key_prefix}_none"):
            st.session_state[ms_key] = []
            selected = []
    return selected

# ---------------------------------------------------------------------------
# íŒŒì¼ ì—…ë¡œë“œ (ì‚¬ì´ë“œë°”)
# ---------------------------------------------------------------------------

with st.sidebar:
    st.header("CSV ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("backdata.csv (cp949) ì—…ë¡œë“œ", type="csv")

if uploaded_file is not None:
    if (
        "file_name" not in st.session_state or
        st.session_state["file_name"] != uploaded_file.name
    ):
        st.session_state["df"] = load_csv(uploaded_file)
        st.session_state["file_name"] = uploaded_file.name

    df: Optional[pd.DataFrame] = st.session_state["df"]
else:
    st.info("ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    df = None

# ---------------------------------------------------------------------------
# ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸
# ---------------------------------------------------------------------------

if df is not None and not df.empty:
    con = duckdb.connect(database=":memory:")
    con.register("data", df)

    # ---------------- í•„í„° ----------------
    with st.sidebar:
        st.header("í•„í„° ì¡°ê±´")
        years_all = df["ì—°ë„"].dropna().astype(int).sort_values().unique().tolist()
        plants_all = df["í”ŒëœíŠ¸"].dropna().astype(int).sort_values().unique().tolist() if "í”ŒëœíŠ¸" in df.columns else []
        groups_all = df["êµ¬ë§¤ê·¸ë£¹"].dropna().astype(int).sort_values().unique().tolist() if "êµ¬ë§¤ê·¸ë£¹" in df.columns else []
        suppliers_all = df["ì—…ì²´í‘œì‹œ"].dropna().sort_values().unique().tolist() if "ì—…ì²´í‘œì‹œ" in df.columns else []

        selected_years = multiselect_with_toggle("ì—°ë„", years_all, years_all, "yr")
        selected_plants = multiselect_with_toggle("í”ŒëœíŠ¸", plants_all, plants_all, "pl") if plants_all else []
        selected_groups = multiselect_with_toggle("êµ¬ë§¤ê·¸ë£¹", groups_all, groups_all, "gr") if groups_all else []
        selected_suppliers = multiselect_with_toggle("ê³µê¸‰ì—…ì²´", suppliers_all, suppliers_all, "sp") if suppliers_all else []

    # ---- SQL WHERE ì ˆ ì¡°ë¦½ ----
    where_parts = [f"ì—°ë„ IN ({sql_list_num(selected_years)})"]
    if plants_all:
        where_parts.append(f"í”ŒëœíŠ¸ IN ({sql_list_num(selected_plants)})")
    if groups_all:
        where_parts.append(f"êµ¬ë§¤ê·¸ë£¹ IN ({sql_list_num(selected_groups)})")
    if suppliers_all:
        # ì„ íƒëœ í‘œì‹œê°’ -> ì´ë¦„ íŒŒì‹± (ì½”ë“œ_ì´ë¦„ â†’ ì´ë¦„)
        supplier_names = [s.split("_", 1)[1] if "_" in s else s for s in selected_suppliers]
        where_parts.append(f"ê³µê¸‰ì—…ì²´ëª… IN ({sql_list_str(supplier_names)})")

    filter_where = " WHERE " + " AND ".join(where_parts)

    # ---------------- ì›”ë³„ ì‹œê³„ì—´ ì§‘ê³„ ----------------
    month_df = con.execute(
        f"""
        SELECT date_trunc('month', ë§ˆê°ì›”) AS ì—°ì›”,
               ROUND(SUM(ì†¡ì¥ìˆ˜ëŸ‰) / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
               ROUND(SUM(ì†¡ì¥ê¸ˆì•¡) / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
        FROM data
        {filter_where}
        GROUP BY 1
        ORDER BY 1
        """
    ).fetchdf()
    month_df["ì—°ì›”í‘œì‹œ"] = month_df["ì—°ì›”"].dt.strftime("%Yë…„%mì›”")

    st.title("ğŸ“ˆ ì›”ë³„ êµ¬ë§¤ í˜„í™©")
    st.dataframe(month_df[["ì—°ì›”í‘œì‹œ", "ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA", "ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›"]], hide_index=True, use_container_width=True)

    if not month_df.empty:
        line = (
            alt.Chart(month_df)
            .mark_line(point=True)
            .encode(
                x=alt.X("ì—°ì›”:T", title="ì—°ì›”"),
                y=alt.Y("ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›:Q", title="ê¸ˆì•¡(ë°±ë§Œ ì›)"),
                tooltip=["ì—°ì›”í‘œì‹œ:N", "ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA:Q", "ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›:Q"]
            )
            .interactive()
        )
        st.altair_chart(line, use_container_width=True)
    st.caption("ë‹¨ìœ„: ì†¡ì¥ìˆ˜ëŸ‰ = ì²œ EA, ì†¡ì¥ê¸ˆì•¡ = ë°±ë§Œ ì›")

    # ---------------- ì—…ì²´ë³„ ì§‘ê³„ ----------------
    if suppliers_all:
        sup_df = con.execute(
            f"""
            SELECT ê³µê¸‰ì—…ì²´ëª…,
                   ROUND(SUM(ì†¡ì¥ìˆ˜ëŸ‰) / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
                   ROUND(SUM(ì†¡ì¥ê¸ˆì•¡) / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
            FROM data
            {filter_where}
            GROUP BY 1
            ORDER BY 2 DESC
            """
        ).fetchdf()

        st.markdown("---")
        st.header("ğŸ¢ ì—…ì²´ë³„ êµ¬ë§¤ í˜„í™©")
        st.dataframe(sup_df, hide_index=True, use_container_width=True)

        if not sup_df.empty:
            sup_csv = sup_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button("ì—…ì²´ë³„ CSV ë‹¤ìš´ë¡œë“œ", sup_csv, file_name="supplier_summary.csv", mime="text/csv")

    # ---------------- ìì¬ëª… ê²€ìƒ‰ ----------------
    st.markdown("---")
    st.header("ğŸ” ìì¬ëª… ê²€ìƒ‰ (ì™€ì¼ë“œì¹´ë“œ: *)")
    keyword = st.text_input("ìì¬ëª… íŒ¨í„´ ì˜ˆ) *í¼í“¸*1L*")

    if keyword:
        pattern_sql = keyword.replace("*", "%").replace("'", "''")
        search_where = filter_where + f" AND ìì¬ëª… ILIKE '{pattern_sql}'"

        select_cols = "ë§ˆê°ì›”, ì—°ì›”, ì—°ë„, í”ŒëœíŠ¸, êµ¬ë§¤ê·¸ë£¹, "
        if suppliers_all:
            select_cols += "ê³µê¸‰ì—…ì²´ëª…, "
        search_df = con.execute(
            f"""
            SELECT {select_cols}ìì¬ AS ìì¬ì½”ë“œ,
                   ìì¬ëª…,
                   ROUND(ì†¡ì¥ìˆ˜ëŸ‰ / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
                   ROUND(ì†¡ì¥ê¸ˆì•¡ / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
            FROM data
            {search_where}
            ORDER BY ë§ˆê°ì›”
            """
        ).fetchdf()

        st.write(f"ê²€ìƒ‰ ê²°ê³¼: **{len(search_df):,}ê±´** ì¼ì¹˜")
        st.dataframe(search_df, use_container_width=True)

        if not search_df.empty:
            csv_bytes = search
