# backdata_dashboard.py
"""êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ (Streamlit + DuckDB)

- **íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹**: ì•± ì‹¤í–‰ í›„ CSV(ì¸ì½”ë”© cp949)ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤.
- **í•„í„°**: ì—°ë„(ë§ˆê°ì›”â†’ì—°ë„), í”ŒëœíŠ¸, êµ¬ë§¤ê·¸ë£¹
- **ì§‘ê³„**: ì—°ë„ë³„ ì†¡ì¥ìˆ˜ëŸ‰(ì²œâ€¯EA), ì†¡ì¥ê¸ˆì•¡(ë°±ë§Œâ€¯ì›)
- **ê¸°ëŠ¥**: ìì¬ëª… ë¶€ë¶„ ê²€ìƒ‰, ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ(UTFâ€‘8â€¯BOM)

ì‹¤í–‰::
    streamlit run backdata_dashboard.py
"""

from __future__ import annotations

from io import BytesIO
from typing import Optional

import duckdb
import pandas as pd
import streamlit as st

st.set_page_config(page_title="êµ¬ë§¤ ë°ì´í„° ëŒ€ì‹œë³´ë“œ", layout="wide")

# ---------------------------------------------------------------------------
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------------------------

def load_csv(upload: BytesIO) -> pd.DataFrame:
    """ì—…ë¡œë“œëœ CSV(bytes) â†’ DataFrame ë³€í™˜ ë° ì „ì²˜ë¦¬"""
    df = pd.read_csv(upload, encoding="cp949", low_memory=False)

    # ë‚ ì§œ ë³€í™˜ â†” ì—°ë„ ì»¬ëŸ¼ ìƒì„±
    df["ë§ˆê°ì›”"] = pd.to_datetime(df["ë§ˆê°ì›”"], errors="coerce")
    df["ì—°ë„"] = df["ë§ˆê°ì›”"].dt.year.astype("Int64")

    # ìˆ«ìí˜• ì»¬ëŸ¼ ì •ë¦¬
    df["ì†¡ì¥ìˆ˜ëŸ‰"] = pd.to_numeric(df["ì†¡ì¥ìˆ˜ëŸ‰"], errors="coerce").fillna(0)
    df["ì†¡ì¥ê¸ˆì•¡"] = pd.to_numeric(df["ì†¡ì¥ê¸ˆì•¡"], errors="coerce").fillna(0)

    return df


def list_to_sql_in(values: list) -> str:
    """Python ë¦¬ìŠ¤íŠ¸ë¥¼ SQL IN ì ˆ ë¬¸ìì—´ë¡œ ë³€í™˜ (ë¹„ì–´ìˆìœ¼ë©´ NULL ë°©ì§€ìš© dummy)"""
    return ",".join(map(str, values)) if values else "-1"  # ì¡´ì¬í•˜ì§€ ì•Šì„ ê°’

# ---------------------------------------------------------------------------
# ì‚¬ì´ë“œë°” â€“ CSV ì—…ë¡œë“œ
# ---------------------------------------------------------------------------

with st.sidebar:
    st.header("CSV ì—…ë¡œë“œ")
    uploaded_file = st.file_uploader("backdata.csv (cp949) ì—…ë¡œë“œ", type="csv")

# ---------------------------------------------------------------------------
# ë°ì´í„° ì¤€ë¹„ (Session State í™œìš©)
# ---------------------------------------------------------------------------

if uploaded_file:
    if "df" not in st.session_state or st.session_state["file_id"] != uploaded_file.id:
        st.session_state["df"] = load_csv(uploaded_file)
        st.session_state["file_id"] = uploaded_file.id  # ìƒˆ íŒŒì¼ ì—…ë¡œë“œ ì—¬ë¶€ ì²´í¬

    df = st.session_state["df"]
else:
    st.info("ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
    df: Optional[pd.DataFrame] = None

# ---------------------------------------------------------------------------
# ëŒ€ì‹œë³´ë“œ ë³¸ë¬¸ (íŒŒì¼ ì—…ë¡œë“œ í›„ í‘œì‹œ)
# ---------------------------------------------------------------------------

if df is not None and not df.empty:
    # DuckDB ì—°ê²° (ë§¤ ìš”ì²­ë§ˆë‹¤ ë©”ëª¨ë¦¬ DB ìƒˆë¡œ ìƒì„±í•˜ì—¬ ë°ì´í„° ë“±ë¡)
    con = duckdb.connect(database=":memory:")
    con.register("data", df)

    # -------------------- í•„í„° --------------------
    with st.sidebar:
        st.header("í•„í„° ì¡°ê±´")
        years_all = df["ì—°ë„"].dropna().astype(int).sort_values().unique().tolist()
        plants_all = df["í”ŒëœíŠ¸"].dropna().astype(int).sort_values().unique().tolist()
        groups_all = df["êµ¬ë§¤ê·¸ë£¹"].dropna().astype(int).sort_values().unique().tolist()

        selected_years = st.multiselect("ì—°ë„", years_all, default=years_all)
        selected_plants = st.multiselect("í”ŒëœíŠ¸", plants_all, default=plants_all)
        selected_groups = st.multiselect("êµ¬ë§¤ê·¸ë£¹", groups_all, default=groups_all)

    year_clause = list_to_sql_in(selected_years)
    plant_clause = list_to_sql_in(selected_plants)
    group_clause = list_to_sql_in(selected_groups)

    # -------------------- ì§‘ê³„ ì¿¼ë¦¬ --------------------
    agg_sql = f"""
        SELECT
            ì—°ë„,
            ROUND(SUM(ì†¡ì¥ìˆ˜ëŸ‰) / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
            ROUND(SUM(ì†¡ì¥ê¸ˆì•¡) / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
        FROM data
        WHERE ì—°ë„ IN ({year_clause})
          AND í”ŒëœíŠ¸ IN ({plant_clause})
          AND êµ¬ë§¤ê·¸ë£¹ IN ({group_clause})
        GROUP BY 1
        ORDER BY 1
    """
    result_df = con.execute(agg_sql).fetchdf()

    # -------------------- ì‹œê°í™”/í‘œ --------------------
    st.title("ğŸ“Š ì—°ë„ë³„ êµ¬ë§¤ í˜„í™©")
    st.dataframe(result_df, hide_index=True, use_container_width=True)

    if not result_df.empty:
        st.line_chart(result_df.set_index("ì—°ë„"))
    st.caption("ë‹¨ìœ„: ì†¡ì¥ìˆ˜ëŸ‰ = ì²œ EA, ì†¡ì¥ê¸ˆì•¡ = ë°±ë§Œ ì›")

    # -------------------- ìì¬ëª… ë¶€ë¶„ ê²€ìƒ‰ --------------------
    st.markdown("---")
    st.header("ğŸ” ìì¬ëª… ê²€ìƒ‰")
    keyword = st.text_input("ìì¬ëª…(ì¼ë¶€ ë¬¸ìì—´ ì…ë ¥ ê°€ëŠ¥)")

    if keyword:
        safe_kw = keyword.replace("'", "''")
        search_sql = f"""
            SELECT ë§ˆê°ì›”, ì—°ë„, í”ŒëœíŠ¸, êµ¬ë§¤ê·¸ë£¹,
                   ìì¬   AS ìì¬ì½”ë“œ,
                   ìì¬ëª…,
                   ROUND(ì†¡ì¥ìˆ˜ëŸ‰ / 1000, 2)  AS ì†¡ì¥ìˆ˜ëŸ‰_ì²œEA,
                   ROUND(ì†¡ì¥ê¸ˆì•¡ / 1000000, 2) AS ì†¡ì¥ê¸ˆì•¡_ë°±ë§Œì›
            FROM data
            WHERE ìì¬ëª… ILIKE '%{safe_kw}%'
            ORDER BY ë§ˆê°ì›”
        """
        search_df = con.execute(search_sql).fetchdf()

        st.write(f"ê²€ìƒ‰ ê²°ê³¼: **{len(search_df):,}ê±´** ì¼ì¹˜")
        st.dataframe(search_df, use_container_width=True)

        if not search_df.empty:
            csv_bytes = search_df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
            st.download_button(
                "CSV ë‹¤ìš´ë¡œë“œ", csv_bytes, file_name=f"search_{keyword}.csv", mime="text/csv"
            )
    else:
        st.info("ìì¬ëª…ì„ ì…ë ¥í•˜ì‹œë©´ ê²€ìƒ‰ ê²°ê³¼ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
